{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# VGG16 model comparison","metadata":{}},{"cell_type":"markdown","source":"In this notebook, a modern convolution model called 'VGG16' is applied to the already known Chest X-rays data, which present unbalanced classes.\n\nThe power of the VGG16 model has already been demonstrated on these data, so the purpose of this book is to compare the following models:\n\n1) VGG16 with no bias and no class weights \n\n2) VGG16 with no bias and with class weights\n\n3) VGG16 with bias and with no class weights\n\n4) VGG16 with bias and with class weights\n\nThe question to ask is: is proper data engineering on data with unbalanced classes really necessary to obtain better accuracy values?","metadata":{}},{"cell_type":"markdown","source":"**RESULTS**: VGG16 with bias and with class weights is the best model, with the following performance:\n\nLoss on test set:  2.613898992538452\n\nAccuracy on test set:  0.7932692170143127","metadata":{}},{"cell_type":"markdown","source":"# Step 1: Data reading and insight","metadata":{}},{"cell_type":"code","source":"import glob\nimport os\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport tensorflow as tf\nimport sklearn\nfrom tensorflow import keras\n#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom keras.layers import Dense, Conv2D, MaxPool2D , Flatten\nfrom keras.models import Sequential\nfrom keras import initializers\nfrom keras.preprocessing.image import ImageDataGenerator\n\nseed = 12\nnp.random.seed(seed)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:25:26.050500Z","iopub.execute_input":"2022-07-25T11:25:26.053175Z","iopub.status.idle":"2022-07-25T11:25:31.490810Z","shell.execute_reply.started":"2022-07-25T11:25:26.053128Z","shell.execute_reply":"2022-07-25T11:25:31.489450Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"dir_path = \"../input/chest-xray-pneumonia/chest_xray/\"","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:25:34.446914Z","iopub.execute_input":"2022-07-25T11:25:34.447794Z","iopub.status.idle":"2022-07-25T11:25:34.452523Z","shell.execute_reply.started":"2022-07-25T11:25:34.447756Z","shell.execute_reply":"2022-07-25T11:25:34.451506Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"''' training path '''\ntrain_p = os.path.join(dir_path, \"train\")\n\n''' test path '''\ntest_p =os.path.join(dir_path, \"test\")\n\n''' val path '''\nval_p = os.path.join(dir_path, \"val\")","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:25:38.520583Z","iopub.execute_input":"2022-07-25T11:25:38.520968Z","iopub.status.idle":"2022-07-25T11:25:38.527294Z","shell.execute_reply.started":"2022-07-25T11:25:38.520933Z","shell.execute_reply":"2022-07-25T11:25:38.526184Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"''' PNEUMONIA images '''\np_train_images = glob.glob(train_p + \"/PNEUMONIA/*.jpeg\")\n\n''' NORMAL  images '''\nn_train_images = glob.glob(train_p + \"/NORMAL/*.jpeg\")","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:25:41.736109Z","iopub.execute_input":"2022-07-25T11:25:41.736727Z","iopub.status.idle":"2022-07-25T11:25:42.062689Z","shell.execute_reply.started":"2022-07-25T11:25:41.736690Z","shell.execute_reply":"2022-07-25T11:25:42.061622Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Step 2: EDA","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame(np.concatenate([[0]*len(n_train_images) , [1] *  len(p_train_images)]),columns=[\"class\"])","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:25:46.368388Z","iopub.execute_input":"2022-07-25T11:25:46.368758Z","iopub.status.idle":"2022-07-25T11:25:46.376832Z","shell.execute_reply.started":"2022-07-25T11:25:46.368725Z","shell.execute_reply":"2022-07-25T11:25:46.375697Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"sns.countplot(df['class'],data=df)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:25:51.342166Z","iopub.execute_input":"2022-07-25T11:25:51.342517Z","iopub.status.idle":"2022-07-25T11:25:51.540717Z","shell.execute_reply.started":"2022-07-25T11:25:51.342490Z","shell.execute_reply":"2022-07-25T11:25:51.539805Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"**Examine the class label imbalance**\n\nLet's look at the dataset imbalance:","metadata":{}},{"cell_type":"code","source":"neg, pos = np.bincount(df['class'])\ntotal = neg + pos\nprint('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n    total, pos, 100 * pos / total))","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:25:56.487413Z","iopub.execute_input":"2022-07-25T11:25:56.488249Z","iopub.status.idle":"2022-07-25T11:25:56.498209Z","shell.execute_reply.started":"2022-07-25T11:25:56.488199Z","shell.execute_reply":"2022-07-25T11:25:56.497192Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"The positive class accounts for 74.29% of total","metadata":{}},{"cell_type":"markdown","source":"# Step 3: Data Preparation","metadata":{}},{"cell_type":"markdown","source":"ImageDataGenerator's goal is to make it simple to input data with labels into the model. It is a highly useful class since it includes various functions for data augmentation. The most notable benefit of this class is that it has no effect on the data stored on disk. This class changes the data as it is passed to the model.","metadata":{}},{"cell_type":"code","source":"trdata = ImageDataGenerator()\ntraindata = trdata.flow_from_directory(train_p, target_size = (224,224))\n\nvldata = ImageDataGenerator()\nvaldata = vldata.flow_from_directory(val_p, target_size = (224,224))\n\ntsdata = ImageDataGenerator()\ntestdata = tsdata.flow_from_directory(test_p, target_size = (224,224))","metadata":{"execution":{"iopub.status.busy":"2022-07-25T13:07:28.138041Z","iopub.execute_input":"2022-07-25T13:07:28.138935Z","iopub.status.idle":"2022-07-25T13:07:29.722401Z","shell.execute_reply.started":"2022-07-25T13:07:28.138890Z","shell.execute_reply":"2022-07-25T13:07:29.721266Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"# Step 4: Modelling","metadata":{}},{"cell_type":"markdown","source":"INFO: the VGG Network can be partitioned into two parts: the first consisting mostly of convolutional and pooling layers and the second consisting of fully connected layers. The convolutional layers are grouped in nonlinear transformations that leave the dimensonality unchanged, followed by a resolution-reduction step (See [https://d2l.ai/chapter_convolutional-modern/vgg.html](http://))","metadata":{}},{"cell_type":"markdown","source":"1) VGG16 with no bias and no class weights ","metadata":{}},{"cell_type":"code","source":"# VGG16 Model\n\nmodel_1 = Sequential()\nmodel_1.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel_1.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel_1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel_1.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_1.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel_1.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_1.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_1.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel_1.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_1.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_1.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel_1.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_1.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_1.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel_1.add(Flatten())\nmodel_1.add(Dense(units=4096,activation=\"relu\"))\nmodel_1.add(Dense(units=4096,activation=\"relu\"))\nmodel_1.add(Dense(units=2, activation=\"softmax\"))","metadata":{"execution":{"iopub.status.busy":"2022-07-25T09:28:54.879009Z","iopub.execute_input":"2022-07-25T09:28:54.879397Z","iopub.status.idle":"2022-07-25T09:28:56.231240Z","shell.execute_reply.started":"2022-07-25T09:28:54.879346Z","shell.execute_reply":"2022-07-25T09:28:56.230256Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Here I will be using Adam optimiser to reach to the global minima while training out model. I set lr = 0.0001 with decay rate = 0.00001","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\nopt = Adam(learning_rate=0.0001, decay=1e-5)\n\nmodel_1.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-07-25T09:29:00.367489Z","iopub.execute_input":"2022-07-25T09:29:00.367856Z","iopub.status.idle":"2022-07-25T09:29:00.384230Z","shell.execute_reply.started":"2022-07-25T09:29:00.367827Z","shell.execute_reply":"2022-07-25T09:29:00.383073Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nnb_epochs = 20\n\n\n# Define the number of training steps\nnb_train_steps = total//batch_size","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:28:27.957855Z","iopub.execute_input":"2022-07-25T11:28:27.958560Z","iopub.status.idle":"2022-07-25T11:28:27.963417Z","shell.execute_reply.started":"2022-07-25T11:28:27.958523Z","shell.execute_reply":"2022-07-25T11:28:27.962166Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"ModelCheckpoint assists us in saving the model by monitoring a specific parameter of the model. In this scenario, I'm tracking validation accuracy by giving \"val_acc\" to ModelCheckpoint. The model will be stored to disk only if the model's validation accuracy in the current epoch is greater than it was in the previous epoch.\n\nEarlyStopping allows us to end the model's training early if there is no rise in the parameter that I have selected to check in EarlyStopping. In this scenario, I'm tracking validation accuracy by giving \"val_acc\" to EarlyStopping. I've set patience to 5, which indicates that the model will stop training if it doesn't see an increase in validation accuracy after 5 epochs.\n\nI'm using model.fit generator to feed data to the model because I'm also using ImageDataGenerator. I'll provide train and test data to fit generator.","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping\n\ncheckpoint_1 = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\nearly_1 = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1, mode='auto')\nhistory_1 = model_1.fit_generator(generator=traindata,epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n                              validation_data= valdata,callbacks=[checkpoint_1,early_1])","metadata":{"execution":{"iopub.status.busy":"2022-07-25T09:29:09.726653Z","iopub.execute_input":"2022-07-25T09:29:09.727116Z","iopub.status.idle":"2022-07-25T09:51:22.986275Z","shell.execute_reply.started":"2022-07-25T09:29:09.727069Z","shell.execute_reply":"2022-07-25T09:51:22.985386Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history_1.history[\"accuracy\"])\nplt.plot(history_1.history['val_accuracy'])\nplt.plot(history_1.history['loss'])\nplt.plot(history_1.history['val_loss'])\nplt.title(\"Performance for VGG16 with no bias and no class weights\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T09:53:42.762636Z","iopub.execute_input":"2022-07-25T09:53:42.763221Z","iopub.status.idle":"2022-07-25T09:53:42.985522Z","shell.execute_reply.started":"2022-07-25T09:53:42.763184Z","shell.execute_reply":"2022-07-25T09:53:42.984586Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Evaluation on test dataset\ntest_loss, test_score = model_1.evaluate(testdata, batch_size=16)\nprint(\"Loss on test set: \", test_loss)\nprint(\"Accuracy on test set: \", test_score)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T09:54:06.877218Z","iopub.execute_input":"2022-07-25T09:54:06.877730Z","iopub.status.idle":"2022-07-25T09:54:13.977868Z","shell.execute_reply.started":"2022-07-25T09:54:06.877690Z","shell.execute_reply":"2022-07-25T09:54:13.976810Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"2) VGG16 with no bias and with class weights","metadata":{}},{"cell_type":"code","source":"# Scaling by total/2 helps keep the loss to a similar magnitude.\n# The sum of the weights of all examples stays the same.\nweight_for_0 = (1 / neg)*(total)/2.0 \nweight_for_1 = (1 / pos)*(total)/2.0\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:30:36.487626Z","iopub.execute_input":"2022-07-25T11:30:36.488300Z","iopub.status.idle":"2022-07-25T11:30:36.494605Z","shell.execute_reply.started":"2022-07-25T11:30:36.488263Z","shell.execute_reply":"2022-07-25T11:30:36.493385Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# VGG16 Model\n\nmodel_2 = Sequential()\nmodel_2.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel_2.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel_2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel_2.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_2.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel_2.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_2.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_2.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel_2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel_2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel_2.add(Flatten())\nmodel_2.add(Dense(units=4096,activation=\"relu\"))\nmodel_2.add(Dense(units=4096,activation=\"relu\"))\nmodel_2.add(Dense(units=2, activation=\"softmax\"))","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:57:27.298578Z","iopub.execute_input":"2022-07-25T11:57:27.299078Z","iopub.status.idle":"2022-07-25T11:57:27.527831Z","shell.execute_reply.started":"2022-07-25T11:57:27.299036Z","shell.execute_reply":"2022-07-25T11:57:27.526908Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model_2.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:57:31.986383Z","iopub.execute_input":"2022-07-25T11:57:31.986740Z","iopub.status.idle":"2022-07-25T11:57:31.997827Z","shell.execute_reply.started":"2022-07-25T11:57:31.986708Z","shell.execute_reply":"2022-07-25T11:57:31.996887Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping\n\ncheckpoint_2 = ModelCheckpoint(\"vgg16_2.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\nearly_2 = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1, mode='auto')\nhistory_2 = model_2.fit_generator(generator=traindata,epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n                              validation_data= valdata,callbacks=[checkpoint_2,early_2], class_weight = {0: weight_for_0, 1: weight_for_1})","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:57:34.653031Z","iopub.execute_input":"2022-07-25T11:57:34.653649Z","iopub.status.idle":"2022-07-25T12:22:21.598652Z","shell.execute_reply.started":"2022-07-25T11:57:34.653614Z","shell.execute_reply":"2022-07-25T12:22:21.597635Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history_2.history[\"accuracy\"])\nplt.plot(history_2.history['val_accuracy'])\nplt.plot(history_2.history['loss'])\nplt.plot(history_2.history['val_loss'])\nplt.title(\"Performance for VGG16 with no bias and class weights\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T12:22:30.024842Z","iopub.execute_input":"2022-07-25T12:22:30.025900Z","iopub.status.idle":"2022-07-25T12:22:30.258743Z","shell.execute_reply.started":"2022-07-25T12:22:30.025829Z","shell.execute_reply":"2022-07-25T12:22:30.257691Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Evaluation on test dataset\ntest_loss, test_score = model_2.evaluate(testdata, batch_size=16)\nprint(\"Loss on test set: \", test_loss)\nprint(\"Accuracy on test set: \", test_score)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T12:22:35.784158Z","iopub.execute_input":"2022-07-25T12:22:35.784506Z","iopub.status.idle":"2022-07-25T12:22:42.467541Z","shell.execute_reply.started":"2022-07-25T12:22:35.784476Z","shell.execute_reply":"2022-07-25T12:22:42.466432Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"3) VGG16 with bias and no class weights","metadata":{}},{"cell_type":"code","source":"initial_bias = np.log([pos/neg])\ninitial_bias","metadata":{"execution":{"iopub.status.busy":"2022-07-25T13:07:55.124658Z","iopub.execute_input":"2022-07-25T13:07:55.125041Z","iopub.status.idle":"2022-07-25T13:07:55.133539Z","shell.execute_reply.started":"2022-07-25T13:07:55.125009Z","shell.execute_reply":"2022-07-25T13:07:55.132378Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# VGG16 Model\n\nmodel_3 = Sequential()\nmodel_3.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel_3.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel_3.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel_3.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_3.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_3.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel_3.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_3.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_3.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_3.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel_3.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_3.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_3.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_3.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel_3.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_3.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_3.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_3.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel_3.add(Flatten())\nmodel_3.add(Dense(units=4096,activation=\"relu\"))\nmodel_3.add(Dense(units=4096,activation=\"relu\"))\nmodel_3.add(Dense(units=2, activation=\"softmax\", bias_initializer=initializers.Constant(initial_bias)))","metadata":{"execution":{"iopub.status.busy":"2022-07-25T13:07:58.611151Z","iopub.execute_input":"2022-07-25T13:07:58.611603Z","iopub.status.idle":"2022-07-25T13:07:58.813720Z","shell.execute_reply.started":"2022-07-25T13:07:58.611563Z","shell.execute_reply":"2022-07-25T13:07:58.812569Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"model_3.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-07-25T13:08:02.784544Z","iopub.execute_input":"2022-07-25T13:08:02.784898Z","iopub.status.idle":"2022-07-25T13:08:02.796062Z","shell.execute_reply.started":"2022-07-25T13:08:02.784849Z","shell.execute_reply":"2022-07-25T13:08:02.795188Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping\n\ncheckpoint_3 = ModelCheckpoint(\"vgg16_3.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\nearly_3 = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1, mode='auto')\nhistory_3 = model_3.fit_generator(generator=traindata,epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n                              validation_data= valdata,callbacks=[checkpoint_3,early_3])","metadata":{"execution":{"iopub.status.busy":"2022-07-25T13:08:07.091045Z","iopub.execute_input":"2022-07-25T13:08:07.091388Z","iopub.status.idle":"2022-07-25T13:30:47.759618Z","shell.execute_reply.started":"2022-07-25T13:08:07.091360Z","shell.execute_reply":"2022-07-25T13:30:47.758612Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history_3.history[\"accuracy\"])\nplt.plot(history_3.history['val_accuracy'])\nplt.plot(history_3.history['loss'])\nplt.plot(history_3.history['val_loss'])\nplt.title(\"Performance for VGG16 with bias and no class weights\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T13:30:52.733385Z","iopub.execute_input":"2022-07-25T13:30:52.733741Z","iopub.status.idle":"2022-07-25T13:30:52.961269Z","shell.execute_reply.started":"2022-07-25T13:30:52.733711Z","shell.execute_reply":"2022-07-25T13:30:52.960391Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# Evaluation on test dataset\ntest_loss, test_score = model_3.evaluate(testdata, batch_size=16)\nprint(\"Loss on test set: \", test_loss)\nprint(\"Accuracy on test set: \", test_score)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T13:31:05.825095Z","iopub.execute_input":"2022-07-25T13:31:05.825442Z","iopub.status.idle":"2022-07-25T13:31:12.184595Z","shell.execute_reply.started":"2022-07-25T13:31:05.825411Z","shell.execute_reply":"2022-07-25T13:31:12.183564Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"4) VGG16 with bias and with class weights","metadata":{}},{"cell_type":"code","source":"# VGG16 Model\n\nmodel_4 = Sequential()\nmodel_4.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel_4.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel_4.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel_4.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_4.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_4.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel_4.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_4.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_4.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_4.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel_4.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_4.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_4.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_4.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel_4.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_4.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_4.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel_4.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel_4.add(Flatten())\nmodel_4.add(Dense(units=4096,activation=\"relu\"))\nmodel_4.add(Dense(units=4096,activation=\"relu\"))\nmodel_4.add(Dense(units=2, activation=\"softmax\", bias_initializer=initializers.Constant(initial_bias)))","metadata":{"execution":{"iopub.status.busy":"2022-07-25T13:31:28.861359Z","iopub.execute_input":"2022-07-25T13:31:28.861716Z","iopub.status.idle":"2022-07-25T13:31:29.020903Z","shell.execute_reply.started":"2022-07-25T13:31:28.861687Z","shell.execute_reply":"2022-07-25T13:31:29.019978Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"model_4.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-07-25T13:31:30.160550Z","iopub.execute_input":"2022-07-25T13:31:30.161539Z","iopub.status.idle":"2022-07-25T13:31:30.172045Z","shell.execute_reply.started":"2022-07-25T13:31:30.161486Z","shell.execute_reply":"2022-07-25T13:31:30.171086Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping\n\ncheckpoint_4 = ModelCheckpoint(\"vgg16_4.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\nearly_4 = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1, mode='auto')\nhistory_4 = model_4.fit_generator(generator=traindata,epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n                                 validation_data= valdata,callbacks=[checkpoint_4,early_4], class_weight = {0: weight_for_0, 1: weight_for_1})\n","metadata":{"execution":{"iopub.status.busy":"2022-07-25T13:31:34.691316Z","iopub.execute_input":"2022-07-25T13:31:34.691663Z","iopub.status.idle":"2022-07-25T13:56:33.842493Z","shell.execute_reply.started":"2022-07-25T13:31:34.691633Z","shell.execute_reply":"2022-07-25T13:56:33.841505Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history_4.history[\"accuracy\"])\nplt.plot(history_4.history['val_accuracy'])\nplt.plot(history_4.history['loss'])\nplt.plot(history_4.history['val_loss'])\nplt.title(\"Performance for VGG16 with bias and class weights\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T13:57:00.981898Z","iopub.execute_input":"2022-07-25T13:57:00.983017Z","iopub.status.idle":"2022-07-25T13:57:01.198813Z","shell.execute_reply.started":"2022-07-25T13:57:00.982973Z","shell.execute_reply":"2022-07-25T13:57:01.196805Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"# Evaluation on test dataset\ntest_loss, test_score = model_4.evaluate(testdata, batch_size=16)\nprint(\"Loss on test set: \", test_loss)\nprint(\"Accuracy on test set: \", test_score)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T13:57:08.354326Z","iopub.execute_input":"2022-07-25T13:57:08.354685Z","iopub.status.idle":"2022-07-25T13:57:18.893402Z","shell.execute_reply.started":"2022-07-25T13:57:08.354652Z","shell.execute_reply":"2022-07-25T13:57:18.892433Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"FINAL RESULTS\n\n**MODEL_4 IS THE BEST MODEL**","metadata":{}}]}